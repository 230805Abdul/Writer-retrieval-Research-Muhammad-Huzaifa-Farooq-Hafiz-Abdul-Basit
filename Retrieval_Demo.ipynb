{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ” CARA-WR: Quick Retrieval Demo\n",
    "This notebook demonstrates writer retrieval on a trained model.\n",
    "\"\"\"\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Project root\n",
    "ROOT = Path('..').resolve()\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "# Setup logging\n",
    "from src.utils.logging_utils import setup_logging\n",
    "logger = setup_logging(name='cara_wr_demo', level=logging.INFO, use_colors=False)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s | %(levelname)-8s | %(message)s',\n",
    "    datefmt='%H:%M:%S',\n",
    "    force=True\n",
    ")\n",
    "\n",
    "logger.info('=' * 60)\n",
    "logger.info('ğŸ” CARA-WR: Writer Retrieval Demo')\n",
    "logger.info('=' * 60)\n",
    "logger.info('')\n",
    "\n",
    "# ===== PATH CONFIGURATION =====\n",
    "# Update these paths to match your experiment\n",
    "DATASET = 'cvl'  # or 'iam'\n",
    "\n",
    "if DATASET == 'cvl':\n",
    "    TEST_CSV = ROOT / 'data' / 'cvl' / 'cvl_test.csv'\n",
    "    CHECKPOINT_DIR = ROOT / 'experiments' / 'cvl' / 'checkpoint'\n",
    "    LABELS_JSON = ROOT / 'data' / 'cvl' / 'cvl_labels.json'\n",
    "elif DATASET == 'iam':\n",
    "    TEST_CSV = ROOT / 'data' / 'iam' / 'iam_test.csv'\n",
    "    CHECKPOINT_DIR = ROOT / 'experiments' / 'iam' / 'checkpoints'\n",
    "    LABELS_JSON = ROOT / 'data' / 'iam' / 'iam_labels.json'\n",
    "\n",
    "logger.info(f'ğŸ“‚ Dataset: {DATASET}')\n",
    "logger.info(f'   Test CSV: {TEST_CSV}')\n",
    "logger.info(f'   Checkpoints: {CHECKPOINT_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a25ae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Run Retrieval Evaluation ===\n",
    "import torch\n",
    "from src.evaluation.eval_retrieval import main as eval_retrieval\n",
    "\n",
    "# Find best checkpoint\n",
    "ckpt_list = sorted(CHECKPOINT_DIR.glob('best_epoch*_loss*.pt'))\n",
    "\n",
    "if ckpt_list:\n",
    "    ckpt_path = ckpt_list[-1]\n",
    "    logger.info(f'ğŸ“‚ Using checkpoint: {ckpt_path.name}')\n",
    "    \n",
    "    # Run evaluation with best settings\n",
    "    eval_args = [\n",
    "        '--csv', str(TEST_CSV),\n",
    "        '--root-dir', str(ROOT),\n",
    "        '--checkpoint', str(ckpt_path),\n",
    "        '--agg-type', 'sum',      # Sum pooling\n",
    "        '--mode', 'auto',         # Quantity-adaptive\n",
    "        '--device', 'cuda',\n",
    "        '--rerank', 'sgr',        # SGR reranking\n",
    "    ]\n",
    "    \n",
    "    sys.argv = ['eval_retrieval.py'] + eval_args\n",
    "    labels, paths, descs, metrics = eval_retrieval()\n",
    "    \n",
    "    logger.info('')\n",
    "    logger.info('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—')\n",
    "    logger.info('â•‘       RETRIEVAL RESULTS            â•‘')\n",
    "    logger.info('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£')\n",
    "    logger.info(f'â•‘  mAP:    {metrics[\"mAP\"]*100:6.2f}%                  â•‘')\n",
    "    logger.info(f'â•‘  Top-1:  {metrics[\"Top1\"]*100:6.2f}%                  â•‘')\n",
    "    logger.info(f'â•‘  Top-5:  {metrics[\"Top5\"]*100:6.2f}%                  â•‘')\n",
    "    logger.info(f'â•‘  Top-10: {metrics[\"Top10\"]*100:6.2f}%                  â•‘')\n",
    "    logger.info('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')\n",
    "else:\n",
    "    logger.warning(f'âš ï¸ No checkpoint found in {CHECKPOINT_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9df8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visualize Retrieval Results ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils.preprocessing import load_image\n",
    "\n",
    "def visualize_retrieval(query_idx, labels, paths, descs, top_k=5):\n",
    "    \"\"\"Show query image and top-k retrieved images.\"\"\"\n",
    "    \n",
    "    # Compute similarity\n",
    "    query_desc = descs[query_idx:query_idx+1]  # [1, D]\n",
    "    sims = (descs @ query_desc.T).squeeze()    # [N]\n",
    "    sims[query_idx] = -1  # Exclude self\n",
    "    \n",
    "    # Get top-k indices\n",
    "    top_indices = np.argsort(-sims)[:top_k]\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, top_k + 1, figsize=(3*(top_k+1), 4))\n",
    "    \n",
    "    # Show query\n",
    "    query_img = load_image(paths[query_idx])\n",
    "    axes[0].imshow(query_img, cmap='gray')\n",
    "    axes[0].set_title(f'Query\\nWriter: {labels[query_idx]}', fontweight='bold', color='blue')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Show retrieved images\n",
    "    query_writer = labels[query_idx]\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        img = load_image(paths[idx])\n",
    "        axes[i+1].imshow(img, cmap='gray')\n",
    "        \n",
    "        writer = labels[idx]\n",
    "        is_correct = (writer == query_writer)\n",
    "        color = 'green' if is_correct else 'red'\n",
    "        marker = 'âœ“' if is_correct else 'âœ—'\n",
    "        \n",
    "        axes[i+1].set_title(f'Rank {i+1} {marker}\\nWriter: {writer}\\nSim: {sims[idx]:.3f}', \n",
    "                           fontweight='bold', color=color)\n",
    "        axes[i+1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize a few queries\n",
    "if 'descs' in dir():\n",
    "    logger.info('ğŸ–¼ï¸ Visualizing sample retrievals...')\n",
    "    for query_idx in [0, 10, 50]:\n",
    "        if query_idx < len(paths):\n",
    "            visualize_retrieval(query_idx, labels, paths, descs, top_k=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
